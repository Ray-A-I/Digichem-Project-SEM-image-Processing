{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b2c209",
   "metadata": {},
   "source": [
    "AE feature extractor, main operator is main().\n",
    "Change image folder to your labeled SEM image folder.\n",
    "Model path to your trained AE model.\n",
    "Output to your desire CSV file name.\n",
    "Combines with template.csv to include full Magpie Features.\n",
    "Specify Latent dimensions, ensure consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ce8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de2c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((144, 256)),  # Your model expects (1, 144, 256)\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc7e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, latent_dim=32):\n",
    "        super(AE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1),   # (B, 32, H/2, W/2)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),  # (B, 64, H/4, W/4)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), # (B, 128, H/8, W/8)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        self.flattened_size = 128 * 18 * 32\n",
    "        self.fc_enc = nn.Linear(self.flattened_size, latent_dim)\n",
    "        self.fc_dec = nn.Linear(latent_dim, self.flattened_size)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # (B, 64, H/4, W/4)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),   # (B, 32, H/2, W/2)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1),    # (B, 1, H, W)\n",
    "            nn.Sigmoid(),  # Output in [0, 1]\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, self.flattened_size)\n",
    "        return self.fc_enc(x)\n",
    "\n",
    "    def decode(self, z):\n",
    "        x = self.fc_dec(z)\n",
    "        x = x.view(-1, 128, 18, 32)\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74dd9951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_image_paths(root_dir, extensions={\".jpg\", \".png\", \".jpeg\", \".bmp\"}):\n",
    "    paths = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for f in filenames:\n",
    "            if any(f.lower().endswith(ext) for ext in extensions):\n",
    "                paths.append(os.path.join(dirpath, f))\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc5120f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_latents(image_paths, model, transform, device):\n",
    "    rows = []\n",
    "    for path in tqdm(image_paths):\n",
    "        try:\n",
    "            image = Image.open(path).convert('L')\n",
    "            image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                latent = model.encode(image_tensor).squeeze().cpu().numpy()\n",
    "            row = [os.path.relpath(path)] + [\"\"] * 4 + latent.tolist()\n",
    "            rows.append(row)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {path}: {e}\")\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87f980f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def save_to_csv(rows, template_csv, output_csv,\n",
    "                              base_header_first4=None):\n",
    "    \"\"\"\n",
    "    rows: list of lists, each row has at least 5 columns followed by extracted features\n",
    "    template_csv: path to template CSV\n",
    "    output_csv: path to save\n",
    "    base_header_first4: list of 4 strings for first 4 columns' headers (optional)\n",
    "    \"\"\"\n",
    "\n",
    "    # Load template\n",
    "    df_template = pd.read_csv(template_csv)\n",
    "\n",
    "    # Get template's header for column 5\n",
    "    col5_name = df_template.columns[4]\n",
    "\n",
    "    # Find start index for \"MagpieData minimum Number\"\n",
    "    if \"MagpieData minimum Number\" not in df_template.columns:\n",
    "        raise ValueError(\"Template does not contain column 'MagpieData minimum Number'.\")\n",
    "    start_idx = df_template.columns.get_loc(\"MagpieData minimum Number\")\n",
    "\n",
    "    # All template headers from that column onward\n",
    "    extra_template_headers = df_template.columns[start_idx:].tolist()\n",
    "\n",
    "    # Build base header (first 4 columns)\n",
    "    if base_header_first4 is None:\n",
    "        base_header_first4 = [\"filename\", \"col2\", \"col3\", \"col4\"]\n",
    "    if len(base_header_first4) != 4:\n",
    "        raise ValueError(\"base_header_first4 must have exactly 4 names.\")\n",
    "\n",
    "    # Determine how many extracted features are in rows\n",
    "    n_extracted_features = len(rows[0]) - 5  # exclude first 5 columns\n",
    "    # We'll append template extra columns later, so just count original features\n",
    "    # If your rows already include template columns, adjust accordingly.\n",
    "\n",
    "    # Feature headers\n",
    "    feature_headers = [f\"f_{i}\" for i in range(n_extracted_features)]\n",
    "\n",
    "    # Final header\n",
    "    final_header = base_header_first4 + [col5_name] + feature_headers + extra_template_headers\n",
    "\n",
    "    # Prepare data from template\n",
    "    col5_values = df_template.iloc[:, 4].tolist()\n",
    "    extra_template_values = df_template.iloc[:, start_idx:].values\n",
    "\n",
    "    new_rows = []\n",
    "    for i, row in enumerate(rows):\n",
    "        if i >= len(df_template):\n",
    "            raise ValueError(\"Template has fewer rows than your data.\")\n",
    "        # Replace 5th column with template col5\n",
    "        merged = list(row)\n",
    "        merged[4] = col5_values[i]\n",
    "        # Append template columns at the end\n",
    "        merged.extend(extra_template_values[i])\n",
    "        new_rows.append(merged)\n",
    "\n",
    "    # Save with header\n",
    "    with open(output_csv, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(final_header)\n",
    "        writer.writerows(new_rows)\n",
    "\n",
    "    print(f\"✅ Saved CSV with extracted features and template columns to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea3c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 344/344 [00:01<00:00, 233.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved CSV with extracted features and template columns to Example AE Features.csv\n",
      "Saved 344 entries to Example AE Features.csv\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    image_folder = r\"Preprocessed Images\\Labeled SEM\\ourimg_normgrey\"\n",
    "    model_path = r\"Trained Models\\Example AE Finetuned Model.pth\"\n",
    "    output_csv = r\"Extracted Features\\Example AE Features.csv\"\n",
    "    template = r'Miscelleous\\template.csv'\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load model\n",
    "    model = AE(latent_dim=2048)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Process images\n",
    "    image_paths = get_all_image_paths(image_folder)\n",
    "    rows = extract_latents(image_paths, model, transform, device)\n",
    "    save_to_csv(rows,template, output_csv)\n",
    "    print(f\"Saved {len(rows)} entries to {output_csv}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b0e09d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
